{"cells":[{"metadata":{},"cell_type":"markdown","source":"## Experiment No. 2 - Implement a simple linear regressor with a single neuron model"},{"metadata":{},"cell_type":"markdown","source":"Source 1 - https://towardsdatascience.com/linear-regression-using-gradient-descent-97a6c8700931\n\n\n### Linear Regression\n\n### Loss Function\n\n#### <div align=\"center\">$E = {1/n}\\sum_{i=0}^{n} (y_i - \\bar{y_i})^2$</div>\n#### <div align=\"center\">$E = {1/n}\\sum_{i=0}^{n} (y_i - (mx_i + c))^2$</div>\n    \n### Gradient Descent\n\n#### <div align=\"center\">$D_m = 1/n\\sum_{i=0}^{n}2(y_i - (mx_i + c))(-x_i)$</div>\n#### <div align=\"center\">$D_m = -2/n\\sum_{i=0}^{n}(x_i)(y_i - \\bar{y_i})$</div>\n    \n#### <div align=\"center\">$D_c = -2/n\\sum_{i=0}^{n}(y_i - \\bar{y_i})$</div>\n\n#### <div align=\"center\">$m = m - L*D_m$</div>\n#### <div align=\"center\">$c = c - L*D_c$</div>"},{"metadata":{},"cell_type":"markdown","source":"- **Data**\n- **Task**\n- **Mathematical Model** - \n- **Loss Function** - Mean Squared Error\n- **Learning Algorithm** - Gradient Descent\n- **Model Evaluation**"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Find the csv filename\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 1. Import Library and Data"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nplt.rcParams['figure.figsize'] = (12.0, 9.0)\n\n# Preprocessing Input data\ndata = pd.read_csv('/kaggle/input/data.csv')\nX = data.iloc[:, 0]\nY = data.iloc[:, 1]\nplt.scatter(X, Y)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 2. Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Building the model\nm = 0\nc = 0\n\nL = 0.0001  # The learning Rate\nepochs = 1000  # The number of iterations to perform gradient descent\n\nn = float(len(X)) # Number of elements in X\n\n#plt.show()\n\n# Performing Gradient Descent \nfor i in range(epochs): \n    Y_pred = m*X + c  # The current predicted value of Y\n    D_m = (-2/n) * sum(X * (Y - Y_pred))  # Derivative wrt m\n    D_c = (-2/n) * sum(Y - Y_pred)  # Derivative wrt c\n    m = m - L * D_m  # Update m\n    c = c - L * D_c  # Update c\n    #print(i)\n    \n    #Below two lines are optional\n#     plt.scatter(X, Y)\n#     plt.plot([min(X), max(X)], [min(Y_pred), max(Y_pred)], color='red') # predicted\n\nprint (m, c)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 3. Predictions"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Making predictions\nY_pred = m*X + c\n\nplt.scatter(X, Y)\nplt.plot([min(X), max(X)], [min(Y_pred), max(Y_pred)], color='red') # predicted\nplt.show()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}